import ast
import json
import logging
import re
from typing import List, Optional, Any, Dict

logging.basicConfig(level=logging.INFO)

# Compile regex patterns once for better performance
_TRUE_PATTERN = re.compile(r'\bTrue\b')
_FALSE_PATTERN = re.compile(r'\bFalse\b')
_NONE_PATTERN = re.compile(r'\bNone\b')
SPECIAL_CHARS = {
    '.': '_',
    '/': '_',
    '\\': '_',
    '-': '_',
    ' ': '_',
    ':': '_',
    ',': '_',
    ';': '_',
    '(': '_',
    ')': '_',
    '[': '_',
    ']': '_',
    '{': '_',
    '}': '_',
    '|': '_',
    '&': '_and_',
    '+': '_plus_',
    '=': '_equals_',
    '*': '_star_',
    '@': '_at_',
    '#': '_hash_',
    '$': '_dollar_',
    '%': '_percent_',
    '!': '_',
    '?': '_',
    '"': '_',
    "'": '_',
    '`': '_',
    '^': '_',
    '~': '_',
    '<': '_',
    '>': '_',
}

def format_depends_on(depends_on: List[str]) -> str:
    """
    Formats a list of dependencies into a Terraform-compatible string.

    Parameters:
        depends_on (List[str]): A list of resource dependencies.

    Returns:
        str: A formatted string representing the dependencies in Terraform syntax.
    """
    if not all(isinstance(dep, str) for dep in depends_on):
        raise ValueError("All dependencies must be strings.")
    return ", ".join([f"azion_edge_application_main_setting.{item}" for item in depends_on])

def extract_hostname(behaviors: List[dict]) -> str:
    """
    Extracts the hostname from Akamai behaviors.

    Parameters:
        behaviors (List[dict]): A list of behaviors from Akamai configuration.

    Returns:
        str: The extracted hostname or a placeholder if not found.
    """
    try:
        origin_behavior = next((b for b in behaviors if b.get("name") == "origin"), {})
        return origin_behavior.get("options", {}).get("hostname", "placeholder.example.com")
    except ValueError as e:
        logging.error(f"Error extracting hostname: {e}")
        return "placeholder.example.com"

def log_conversion_summary(resources: List[dict]) -> None:
    """
    Logs a summary of the resources generated during conversion.

    Parameters:
        resources (List[dict]): A list of resources generated by the conversion process.
    """
    resource_types = [res["type"] for res in resources if "type" in res]

    logging.info(f"Conversion summary: {len(resources)} resources generated.")
    
    if resource_types:
        logging.info(f"Generated resources: {', '.join(set(resource_types))}")

def write_indented(f: Any, content: str, indent_level: int = 0, indent_size: int = 4) -> None:
    """
    Writes indented content to a file.

    Parameters:
        f (file object): The file to write to.
        content (str): The content to write.
        indent_level (int): The level of indentation.
        indent_size (int): The number of spaces per indentation level.
    """
    indentation = " " * (indent_level * indent_size)
    f.write(indentation + content + "\n")

def write_list_items(f: Any, items: List[Any], indent_level: int = 2) -> None:
    """
    Writes a list of items in Terraform format, ensuring no trailing comma.

    Parameters:
        f (file object): The file to write to.
        items (list): The list of items to write.
        indent_level (int): The level of indentation.
    """
    if not isinstance(items, list) or not items:
        raise ValueError("items must be a non-empty list")

    for index, item in enumerate(items):
        comma = "," if index < len(items) - 1 else ""  # Add a comma only if not the last item
        write_indented(f, f"{item}{comma}", indent_level)

def sanitize_name(name: str) -> str:
    """
    Sanitize a name to be used as a Terraform resource name.
    
    Rules:
    1. Only lowercase letters, numbers, and underscores
    2. Must start with a letter
    3. Cannot start with a number or special character
    4. Replace special characters and spaces with underscores
    5. Remove consecutive underscores
    6. Remove leading/trailing special characters
    
    Parameters:
        name (str): Name to sanitize
        
    Returns:
        str: Sanitized name safe for Terraform resource naming
    """
    if not name:
        return "unnamed_resource"
        
    # Step 1: Convert to lowercase and replace special chars with underscore
    sanitized = name.lower()
    
    # Step 2: Replace common special characters and punctuation
    for char, replacement in SPECIAL_CHARS.items():
        sanitized = sanitized.replace(char, replacement)
    
    # Step 3: Handle non-ASCII characters (like accented characters)
    sanitized = ''.join(c if c.isascii() and (c.isalnum() or c == '_') else '_' 
                       for c in sanitized)
    
    # Step 4: Remove consecutive underscores
    while '__' in sanitized:
        sanitized = sanitized.replace('__', '_')
    
    # Step 5: Remove leading/trailing underscores
    sanitized = sanitized.strip('_')
    
    # Step 6: Ensure it starts with a letter
    if not sanitized or not sanitized[0].isalpha():
        sanitized = 'r_' + sanitized
    
    # Step 7: If empty after sanitization, return default name
    if not sanitized:
        return "unnamed_resource"
        
    return sanitized

def compact_and_sanitize(name: str, max_length: int = 90) -> str:
    """
    Compact and sanitize a long path-like string.
    
    Args:
        name (str): Original name.
        max_length (int): Max allowed length.
        
    Returns:
        str: Sanitized and compacted name.
    """
    def compact(name: str) -> str:
        if len(name) <= max_length:
            return name
        
        parts = name.strip('/').split('/')
        if len(parts) <= 2:
            return name[:max_length]
        
        prefix = parts[0]
        suffix = parts[-1]
        
        # Reserve space for prefix + "_cut_" + suffix
        separator = "_cut_"
        available = max_length - len(separator)
        
        max_prefix = available // 2
        max_suffix = available - max_prefix
        
        prefix = prefix[:max_prefix]
        suffix = suffix[-max_suffix:]
        
        return f"{prefix}{separator}{suffix}"

    compacted = compact(sanitize_name(name))
    if compacted.endswith('_'):
        compacted = compacted[:-1]
    return compacted

def clean_and_parse_json(json_string: str) -> Optional[Any]:
    """
    Clean and parse a JSON or HCL string.
    
    :param json_string: String containing the JSON or HCL.
    :return: Parsed object or None if parsing fails.
    """
    if not json_string:
        logging.debug("Empty string provided for parsing.")
        return None

    try:
        # First try to parse as JSON
        try:
            return json.loads(json_string)
        except json.JSONDecodeError:
            logging.debug("String was not initialy a parseable json.")
            pass
        
        # If string starts with ${jsonencode(...)}, extract the content
        if json_string.startswith('${jsonencode(') and json_string.endswith(')}'):
            # Extract content between jsonencode( and the last )
            json_string = json_string[len('${jsonencode('):-2]
            
            # Replace single quotes with double quotes, but only if they're not within a string
            in_string = False
            escaped = False
            result = []
            for char in json_string:
                if char == '\\' and not escaped:
                    escaped = True
                    result.append(char)
                    continue
                    
                if char == '"' and not escaped:
                    in_string = not in_string
                    result.append(char)
                elif char == "'" and not in_string and not escaped:
                    result.append('"')
                else:
                    result.append(char)
                    
                escaped = False
                
            json_string = ''.join(result)
            
            try:
                # Try to parse the cleaned string
                return json.loads(json_string)
            except json.JSONDecodeError:
                pass
                
            try:
                # If that fails, try to evaluate it as a Python literal
                return ast.literal_eval(json_string)
            except ValueError:
                pass
        
        # Try to parse as a plain object
        try:
            json_string = json_string.replace("'", '"')
            return json.loads(json_string)
        except ValueError:
            pass
        
        logging.error("Failed to parse content as either JSON or HCL")
        return None
            
    except ValueError as e:
        logging.error(f"Error parsing content: {str(e)}")
        return None

def parse_ttl(ttl_str: str) -> int:
    """
    Converts a time-to-live (TTL) string into seconds.

    Supported formats:
    - 'Nd' for days (e.g., '2d' -> 172800 seconds)
    - 'Nh' for hours (e.g., '3h' -> 10800 seconds)
    - 'Nm' for minutes (e.g., '45m' -> 2700 seconds)
    - Numeric only for seconds (e.g., '60' -> 60 seconds)

    Parameters:
        ttl_str (str): A string representing the TTL.

    Returns:
        int: The TTL value in seconds.

    Raises:
        ValueError: If the string format is invalid or not supported.
    """
    # Check if the input is a string; raise an error otherwise
    if not isinstance(ttl_str, str):
        raise ValueError(f"Invalid input: expected a string, received {type(ttl_str).__name__}")

    # Remove unnecessary whitespace from the input string
    ttl_str = ttl_str.strip()

    # Check if the string ends with 'd' (days), and convert to seconds if valid
    if ttl_str.endswith('d'):
        value = ttl_str[:-1]  # Extract the numeric part
        if value.isdigit():
            return int(value) * 86400  # Convert days to seconds

    # Check if the string ends with 'h' (hours), and convert to seconds if valid
    elif ttl_str.endswith('h'):
        value = ttl_str[:-1]  # Extract the numeric part
        if value.isdigit():
            return int(value) * 3600  # Convert hours to seconds

    # Check if the string ends with 'm' (minutes), and convert to seconds if valid
    elif ttl_str.endswith('m'):
        value = ttl_str[:-1]  # Extract the numeric part
        if value.isdigit():
            return int(value) * 60  # Convert minutes to seconds

    # If the string contains only digits, interpret it as seconds
    elif ttl_str.isdigit():
        return int(ttl_str)

    # If none of the conditions match, raise a ValueError for invalid format
    raise ValueError(f"Invalid TTL format: {ttl_str}")

def resources_filter_by_type(resources: List[Dict[str, Any]], resource_type: str) -> List[Dict[str, Any]]:
    """
    Filter objects in 'resources' by the 'type' field.

    Parameters:
        resources (List[Dict[str, Any]]): List of objects to be filtered.
        resource_type (str): The value of the 'type' field to search for.

    Returns:
        List[Dict[str, Any]]: List of objects with the 'type' field corresponding to the search value.
    """
    return [resource for resource in resources if resource.get("type") == resource_type]

def resources_filter_by_name(resources: List[Dict[str, Any]], name: str) -> List[Dict[str, Any]]:
    """
    Filter objects in 'resources' by the 'name' field.

    Parameters:
        resources (List[Dict[str, Any]]): List of objects to be filtered.
        name (str): The value of the 'name' field to search for.

    Returns:
        List[Dict[str, Any]]: List of objects with the 'name' field corresponding to the search value.
    """
    return [resource for resource in resources if resource.get("name") == name]

def find_function(function_map: List[Dict[str, Any]], policy_id: str) -> Optional[Dict[str, Any]]:
    """
    Find a function in the function mapping based on a policy ID.

    Parameters:
        function_map (List[Dict[str, Any]]): List of function mappings.
        policy_id (str): The policy ID to match against.

    Returns:
        Optional[Dict[str, Any]]: The matched function mapping or None if not found.
    """
    if not function_map or not policy_id:
        return None
    
    for mapping in function_map:
        if str(mapping.get("policy_id", "")) == str(policy_id):
            return {
                "behavior_name": mapping.get("behavior_name"),
                "function_id": mapping.get("function_id"),
                "args": mapping.get("args", [])
            }
    
    return None

def get_behavior_config(behavior_name: str, args: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Get the behavior configuration based on the behavior name and arguments.

    Parameters:
        behavior_name (str): Name of the behavior (e.g., edgeRedirector, forwardRewrite)
        args (List[Dict[str, Any]]): List of behavior-specific arguments

    Returns:
        Dict[str, Any]: Configuration for the specified behavior
    """
    if not behavior_name or not args:
        return {}

    if behavior_name == "edgeRedirector":
        return {
            "name": "edge_redirector",
            "rules": [
                {
                    "name": arg.get("name", ""),
                    "source": arg.get("matchURL", ""),
                    "target": arg.get("redirectURL", ""),
                    "status_code": arg.get("statusCode", 301),
                    "preserve_query_string": arg.get("useIncomingQueryString", True)
                } for arg in args
            ]
        }
    elif behavior_name == "forwardRewrite":
        return {
            "name": "forward_rewrite",
            "rules": [
                {
                    "name": arg.get("name", ""),
                    "source": arg.get("matchURL", ""),
                    "target": arg.get("forwardURL", ""),
                    "preserve_query_string": arg.get("useIncomingQueryString", True)
                } for arg in args
            ]
        }
    elif behavior_name == "requestControl":
        return {
            "name": "request_control",
            "rules": [
                {
                    "name": arg.get("name", ""),
                    "matches": arg.get("matches", []),
                    "rate": arg.get("rate", {})
                } for arg in args
            ]
        }
    
    return {}

def is_regex(pattern: str) -> bool:
    """
    Check if the given string is a valid regular expression.

    Args:
        pattern (str): The string to check.

    Returns:
        bool: True if it is a valid regex, False otherwise.
    """
    try:
        re.compile(pattern)
        return True
    except re.error:
        return False


def normalize_path_regex(path: str) -> str:
    escaped_path = path.replace('/', '\\/')

    if not is_regex(escaped_path):
        return f'^{re.escape(escaped_path)}$'

    #if re.match(r'^\(\.\*\)\\\\/', path):
    #    return path

    #if '\\/' in path:
    #    return f'{path}'

    #escaped_path = path.replace('/', '\\/')
    return f'{escaped_path}'

def transform_expression(expression: str, value: str) -> str:
    """
    Replace each occurrence of $<number> by %%{{VAR[<number>]}}
    """
    def replacer(match):
        index = match.group(1)
        return f"%%{{{value}[{index}]}}"
    
    # Regex that captures $ followed by one or more digits
    return re.sub(r"\$(\d+)", replacer, expression)

def make_hashable(obj):
    if isinstance(obj, dict):
        return tuple(sorted((k, make_hashable(v)) for k, v in obj.items()))
    elif isinstance(obj, list):
        return tuple(make_hashable(x) for x in obj)
    return obj

def merge_unique(list1: List[Dict[str, Any]], list2: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    combined = list1 + list2
    seen = set()
    result = []

    for item in combined:
        # Create a hashable representation of the item
        item_hashable = make_hashable(item)
        if item_hashable not in seen:
            seen.add(item_hashable)
            result.append(item)

    return result